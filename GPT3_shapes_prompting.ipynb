{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTXJg5gh8Gyt",
        "outputId": "b6d9d73c-8bea-45cb-fda8-17e71f458662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers[torch])\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[torch])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.0+cu118)\n",
            "Collecting accelerate>=0.19.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, accelerate\n",
            "Successfully installed accelerate-0.19.0 huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install 'transformers[torch]'\n",
        "!pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJoTWMdN-JJR",
        "outputId": "bc3afe83-bcf2-42f9-b6f3-665b530d3766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA5TxiqC-IdB"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/GPT-VLU\"\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3tW8Dj_7TM9"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "from utils.setup_utils import parse_and_validate_df, DFExperimentInfo\n",
        "\n",
        "import pandas as pd\n",
        "from dataclasses import fields\n",
        "import openai\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHddyAPgQ4Ip"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.insert(0, PROJECT_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4HXR9iOJg8x"
      },
      "outputs": [],
      "source": [
        "# OPENAI API KEY\n",
        "openai.api_key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-MhibS-88WUV",
        "outputId": "a6fd9faa-f400-4fa0-e207-118b48057a8f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-12948d8f-95be-46d6-8427-520035b2fb7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>gt</th>\n",
              "      <th>options</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wedge</td>\n",
              "      <td>triangle</td>\n",
              "      <td>['triangle', 'rectangle', 'circle']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flag</td>\n",
              "      <td>rectangle</td>\n",
              "      <td>['triangle', 'rectangle', 'circle']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>carrot</td>\n",
              "      <td>triangle</td>\n",
              "      <td>['triangle', 'rectangle', 'circle']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wheel</td>\n",
              "      <td>circle</td>\n",
              "      <td>['triangle', 'rectangle', 'circle']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>towel</td>\n",
              "      <td>rectangle</td>\n",
              "      <td>['triangle', 'rectangle', 'circle']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12948d8f-95be-46d6-8427-520035b2fb7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12948d8f-95be-46d6-8427-520035b2fb7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12948d8f-95be-46d6-8427-520035b2fb7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     word         gt                              options\n",
              "0   wedge   triangle  ['triangle', 'rectangle', 'circle']\n",
              "1    flag  rectangle  ['triangle', 'rectangle', 'circle']\n",
              "2  carrot   triangle  ['triangle', 'rectangle', 'circle']\n",
              "3   wheel     circle  ['triangle', 'rectangle', 'circle']\n",
              "4   towel  rectangle  ['triangle', 'rectangle', 'circle']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading data\n",
        "dataset_path = '/content/gdrive/MyDrive/GPT-VLU/datasets/shape_association.csv'\n",
        "\n",
        "task = 'choice'\n",
        "df = parse_and_validate_df(dataset_path, task)\n",
        "experiment_df = pd.DataFrame(columns=[fields(DFExperimentInfo)])\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V8jaOThOVsr"
      },
      "source": [
        "## Shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOvaaquiSBCR"
      },
      "source": [
        "\n",
        "Possible extra prompts for this:\n",
        "1. ... instead of MASK, should be \n",
        "2. ... \n",
        "3. ... fill in the MASK\n",
        "4. ... replace the MASK with correct word\n",
        "5. ... choose one option from the list: <> to replace MASK\n",
        "6. ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqM2be9ZOXq9"
      },
      "outputs": [],
      "source": [
        "shapes_orig_prompts = [\n",
        "    \"a photo of a MASK shaped WORD\",\n",
        "    \"a photo of a MASK WORD\",\n",
        "    \"a photo of the MASK WORD\",\n",
        "    \"a MASK WORD\",\n",
        "    \"MASK WORD\",\n",
        "    \"an image of a MASK WORD\",\n",
        "    \"a WORD usually has a MASK shape\",\n",
        "    \"WORDs commonly have a MASK shape\",\n",
        "    \"the basic shape of a WORD is MASK\",\n",
        "    \"what is the shape of a WORD? MASK\"\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "W_MP48KTf-g2"
      },
      "outputs": [],
      "source": [
        "def score_model(orig_prompts):\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for index, row in tqdm(df.iterrows()):\n",
        "    w = row['word']\n",
        "    for p in orig_prompts:\n",
        "      p = p.replace(\"WORD\", w)\n",
        "\n",
        "      shapes_options = ['triangle', ' rectangle', ' circle']\n",
        "\n",
        "      options_results = [] \n",
        "      for option in shapes_options:\n",
        "        input_prompt = p.replace(\"MASK\", option)\n",
        "\n",
        "        # Extract features from GPT3 \n",
        "        res = openai.Embedding.create(\n",
        "          model=\"text-similarity-davinci-001\",\n",
        "          input=input_prompt,\n",
        "          max_tokens=3,\n",
        "        )\n",
        "        v = torch.tensor(res['data'][0]['embedding']).squeeze().flatten()\n",
        "        v /= v.norm(p=2, dim=-1, keepdim=True)\n",
        "        v = v.cpu().numpy()\n",
        "        options_results.append(v)\n",
        "\n",
        "      base = torch.tensor(openai.Embedding.create(\n",
        "          model=\"text-similarity-davinci-001\",\n",
        "          input=p.replace(\"MASK\", ''),\n",
        "          max_tokens=3,\n",
        "        )['data'][0]['embedding']).squeeze().flatten()\n",
        "\n",
        "      base /= base.norm(p=2, dim=-1, keepdim=True)\n",
        "      base = base.cpu().numpy()\n",
        "\n",
        "      scores = np.array(options_results) @ np.expand_dims(base, -1)\n",
        "      ind_class = np.argmax(scores)\n",
        "      y_pred.append(shapes_options[ind_class])\n",
        "      y_true.append(row['gt'])\n",
        "\n",
        "  return y_true, y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-3uxISWsf-oS"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred = score_model(shapes_orig_prompts)\n",
        "accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEDREfIxXH8a"
      },
      "source": [
        "## 1. instead of MASK, should be"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9Tk0XHhXQSm"
      },
      "outputs": [],
      "source": [
        "gpt_extra_prompt1 = '. instead of MASK, should be'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8aItC5vO2bh"
      },
      "outputs": [],
      "source": [
        "def retrieve_results_options(orig_prompts, max_new=1):\n",
        "  y_true, y_pred = [], []\n",
        "\n",
        "  for index, row in df.iloc[1:].iterrows():\n",
        "    w = row['word']\n",
        "    gt = row['gt']\n",
        "\n",
        "    for p in orig_prompts:\n",
        "      p = p.replace(\"WORD\", w)\n",
        "      llm_prompt = '. Choose one word from: {} to replace MASK'.format(row['options'])\n",
        "      input_prompt = p + llm_prompt\n",
        "\n",
        "      res = openai.Completion.create(\n",
        "          model=\"text-davinci-003\",\n",
        "          prompt=input_prompt,\n",
        "          max_tokens=2 + max_new,\n",
        "        )\n",
        "      out_p = res['choices'][0]['text'].replace('\\n', '').replace(' ', '').lower()\n",
        "      y_pred.append(out_p)\n",
        "      y_true.append(gt)\n",
        "      \n",
        "  return y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCAlIOIJJL6z",
        "outputId": "87a0bf2e-a828-4642-da52-43ad6791ec8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08703703703703704"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true, y_pred = retrieve_results_options(shapes_orig_prompts)\n",
        "accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwJI1TlqJNrC"
      },
      "outputs": [],
      "source": [
        "def retrieve_results_nooptions(extra_llm_prompt, orig_prompts, max_new=1):\n",
        "  y_true, y_pred = [], []\n",
        "\n",
        "  for index, row in df.iloc[1:].iterrows():\n",
        "    w = row['word']\n",
        "    gt = row['gt']\n",
        "\n",
        "    for p in orig_prompts:\n",
        "      p = p.replace(\"WORD\", w)\n",
        "      input_prompt = p + extra_llm_prompt\n",
        "      res = openai.Completion.create(\n",
        "          model=\"text-davinci-003\",\n",
        "          prompt=input_prompt,\n",
        "          max_tokens=2 + max_new,\n",
        "        )\n",
        "      out_p = res['choices'][0]['text'].replace('\\n', '').replace(' ', '').lower()\n",
        "      y_pred.append(out_p)\n",
        "      y_true.append(gt)\n",
        "      \n",
        "  return y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TpTPuzzAJTFL",
        "outputId": "527329f6-5a0d-486e-df2e-17da6a10c615"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.025"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true, y_pred = retrieve_results_nooptions('. instead of MASK should be', shapes_orig_prompts, max_new=1)\n",
        "accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FEQAoZCHJn4m",
        "outputId": "0fe4f491-885d-44d0-9d0d-a6e43cf90990"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.000925925925925926"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true, y_pred = retrieve_results_nooptions('. MASK can be replaced with', shapes_orig_prompts, max_new=1)\n",
        "accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Y0LXl7Jt4Q",
        "outputId": "7b53e749-95b4-4cd5-c065-733cc418f088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.002777777777777778"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true, y_pred = retrieve_results_nooptions('. Fill in the MASK: ', shapes_orig_prompts, max_new=1)\n",
        "accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTG3Fg9kMSQg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1iKd0wNeRbEdXHlckgfJ7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}